/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    nf-atacseq Nextflow config file
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    ATAC-seq Allelic Imbalance Pipeline with WASP2
----------------------------------------------------------------------------------------
*/

// Plugin configuration
plugins {
    id 'nf-validation@1.1.3'
}

// Pipeline metadata
manifest {
    name            = 'wasp2/nf-atacseq'
    author          = 'WASP2 Team'
    description     = 'ATAC-seq Allelic Imbalance Pipeline with WASP2 mapping bias correction'
    mainScript      = 'main.nf'
    nextflowVersion = '!>=23.04.0'
    version         = '1.0.0'
}

// Default parameters
params {
    // Input/Output
    input                   = null    // Samplesheet CSV (required)
    outdir                  = './results'
    publish_dir_mode        = 'copy'

    // Reference genome
    fasta                   = null    // Reference FASTA (required)
    fasta_fai               = null    // FASTA index (auto-generated if missing)
    bwa_index               = null    // BWA index directory
    bowtie2_index           = null    // Bowtie2 index directory

    // Variant data (required for WASP2)
    vcf                     = null    // VCF/BCF/PGEN variant file
    vcf_tbi                 = null    // VCF tabix index

    // ATAC-seq specific
    peaks                   = null    // Pre-called peaks BED (optional)
    macs_gsize              = 'hs'    // Effective genome size for MACS2

    // Aligner selection
    aligner                 = 'bwa'   // Options: 'bwa', 'bowtie2'

    // WASP2 options
    wasp_min_count          = 10      // Min allele count for AI analysis
    wasp_pseudocount        = 1       // Pseudocount for beta-binomial
    wasp_threads            = 4       // WASP2 internal threads
    wasp_include_indels     = false   // Include indels in analysis
    wasp_phased             = false   // Use phased haplotype model

    // Processing options
    skip_trimming           = false
    skip_fastqc             = false
    skip_dedup              = false
    skip_wasp               = false   // Skip WASP filtering (use original BAM)
    skip_peak_calling       = false   // Require peaks parameter if true
    skip_multiqc            = false

    // Resource limits
    max_cpus                = 16
    max_memory              = '128.GB'
    max_time                = '240.h'

    // Generic options
    help                    = false
    version                 = false
    tracedir                = "${params.outdir}/pipeline_info"
}

// Load configuration files
includeConfig 'conf/base.config'
includeConfig 'conf/modules.config'

// Execution profiles
profiles {
    debug {
        dumpHashes              = true
        process.beforeScript    = 'echo $HOSTNAME'
        cleanup                 = false
    }
    conda {
        conda.enabled           = true
        docker.enabled          = false
        singularity.enabled     = false
        process.conda           = "${projectDir}/../../environment.yml"
    }
    docker {
        docker.enabled          = true
        conda.enabled           = false
        singularity.enabled     = false
        docker.runOptions       = '-u $(id -u):$(id -g)'
    }
    singularity {
        singularity.enabled     = true
        singularity.autoMounts  = true
        conda.enabled           = false
        docker.enabled          = false
    }
    test {
        includeConfig 'conf/test.config'
    }
    test_full {
        includeConfig 'conf/test_full.config'
    }
}

// Execution reports
def trace_timestamp = new java.util.Date().format('yyyy-MM-dd_HH-mm-ss')
timeline {
    enabled = true
    file    = "${params.tracedir}/execution_timeline_${trace_timestamp}.html"
}
report {
    enabled = true
    file    = "${params.tracedir}/execution_report_${trace_timestamp}.html"
}
trace {
    enabled = true
    file    = "${params.tracedir}/execution_trace_${trace_timestamp}.txt"
}
dag {
    enabled = true
    file    = "${params.tracedir}/pipeline_dag_${trace_timestamp}.html"
}

// Export these variables to prevent local Python/Perl libs from conflicting
env {
    PYTHONNOUSERSITE = 1
    R_PROFILE_USER   = "/.Rprofile"
    R_ENVIRON_USER   = "/.Renviron"
}

// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

// Function to ensure resources don't exceed limits
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "WARNING: Invalid max_memory '${params.max_memory}', using default"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "WARNING: Invalid max_time '${params.max_time}', using default"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min(obj, params.max_cpus as int)
        } catch (all) {
            println "WARNING: Invalid max_cpus '${params.max_cpus}', using default"
            return obj
        }
    }
}
