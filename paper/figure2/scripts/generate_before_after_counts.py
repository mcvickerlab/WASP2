#!/usr/bin/env python3
"""
Generate Figure 2 Panel C input: before/after (original vs WASP2-processed) counts for
all three methods (WASP2-Rust, GATK ASEReadCounter, phASER).

Outputs a long-form TSV with one row per (variant, method):
  chrom, pos, method, orig_ref, orig_alt, filt_ref, filt_alt, orig_total, filt_total,
  orig_ref_ratio, filt_ref_ratio, delta_ref_ratio
"""

from __future__ import annotations

import argparse
from io import StringIO
from pathlib import Path

import numpy as np
import pandas as pd


def parse_wasp2_counts(path: Path) -> pd.DataFrame:
    df = pd.read_csv(path, sep="\t")
    if "ref_count" not in df.columns or "alt_count" not in df.columns:
        raise ValueError(f"Unexpected WASP2 counts format: {path}")
    out = df[["chrom", "pos", "ref_count", "alt_count"]].copy()
    out = out.rename(columns={"ref_count": "ref", "alt_count": "alt"})
    return out


def parse_gatk_ase(path: Path) -> pd.DataFrame:
    with path.open("r") as f:
        lines = [line for line in f if not line.startswith("#")]
    if not lines:
        return pd.DataFrame(columns=["chrom", "pos", "ref", "alt"])
    df = pd.read_csv(StringIO("".join(lines)), sep="\t")
    df = df.rename(
        columns={
            "contig": "chrom",
            "position": "pos",
            "refCount": "ref",
            "altCount": "alt",
        }
    )
    return df[["chrom", "pos", "ref", "alt"]].copy()


def parse_phaser_allelic_counts(path: Path) -> pd.DataFrame:
    df = pd.read_csv(path, sep="\t")
    pos_col = "position" if "position" in df.columns else "pos"
    df = df.rename(
        columns={
            "contig": "chrom",
            pos_col: "pos",
            "refCount": "ref",
            "altCount": "alt",
        }
    )
    return df[["chrom", "pos", "ref", "alt"]].copy()


def before_after_for_method(
    method: str, orig: pd.DataFrame, filt: pd.DataFrame, min_total: int
) -> pd.DataFrame:
    orig = orig.copy()
    filt = filt.copy()
    orig["orig_total"] = orig["ref"] + orig["alt"]
    filt["filt_total"] = filt["ref"] + filt["alt"]

    merged = orig.merge(
        filt[["chrom", "pos", "ref", "alt", "filt_total"]],
        on=["chrom", "pos"],
        how="inner",
        suffixes=("_orig", "_filt"),
    )

    merged = merged.rename(
        columns={
            "ref_orig": "orig_ref",
            "alt_orig": "orig_alt",
            "ref_filt": "filt_ref",
            "alt_filt": "filt_alt",
        }
    )

    merged["orig_total"] = merged["orig_ref"] + merged["orig_alt"]
    # filt_total already present but recompute defensively
    merged["filt_total"] = merged["filt_ref"] + merged["filt_alt"]

    if min_total > 0:
        merged = merged[(merged["orig_total"] >= min_total) & (merged["filt_total"] >= min_total)]

    merged["orig_ref_ratio"] = merged["orig_ref"] / merged["orig_total"]
    merged["filt_ref_ratio"] = merged["filt_ref"] / merged["filt_total"]
    merged["delta_ref_ratio"] = merged["filt_ref_ratio"] - merged["orig_ref_ratio"]
    merged["method"] = method

    return merged[
        [
            "chrom",
            "pos",
            "method",
            "orig_ref",
            "orig_alt",
            "filt_ref",
            "filt_alt",
            "orig_total",
            "filt_total",
            "orig_ref_ratio",
            "filt_ref_ratio",
            "delta_ref_ratio",
        ]
    ].copy()


def main() -> None:
    ap = argparse.ArgumentParser()
    ap.add_argument("--dataset", choices=["hg00731"], default="hg00731")
    ap.add_argument("--min-total", type=int, default=10)
    args = ap.parse_args()

    repo_root = Path(
        "/iblm/netapp/data3/jjaureguy/gvl_files/wasp2/WASP2_extensive_evaluation/WASP2_current/cvpc/WASP2-exp"
    )
    data_dir = repo_root / "paper" / "figure2" / "data" / args.dataset

    # Inputs (generated by run_figure2_benchmarks.sh)
    wasp2_orig = data_dir / "wasp2_counts.original.tsv"
    wasp2_filt = data_dir / "wasp2_counts.filtered.tsv"
    # Optional: WASP1-filtered BAM counts produced via WASP2-rust counter on wasp1_final_sorted.bam
    wasp1_filt = data_dir / "wasp1_counts.filtered.tsv"
    gatk_orig = data_dir / "gatk_counts.original.table"
    gatk_filt = data_dir / "gatk_counts.filtered.table"
    phaser_orig = data_dir / "phaser.original.allelic_counts.txt"
    phaser_filt = data_dir / "phaser.filtered.allelic_counts.txt"

    required = [wasp2_orig, wasp2_filt, gatk_orig, gatk_filt, phaser_orig, phaser_filt]
    missing = [p for p in required if not p.exists()]
    if missing:
        raise SystemExit("Missing required inputs:\n" + "\n".join(str(p) for p in missing))

    out_tsv = data_dir / "before_after_counts.tsv"
    stats_path = data_dir / "before_after_counts_stats.txt"

    wasp2_orig_df = parse_wasp2_counts(wasp2_orig)
    wasp2_filt_df = parse_wasp2_counts(wasp2_filt)
    gatk_orig_df = parse_gatk_ase(gatk_orig)
    gatk_filt_df = parse_gatk_ase(gatk_filt)
    phaser_orig_df = parse_phaser_allelic_counts(phaser_orig)
    phaser_filt_df = parse_phaser_allelic_counts(phaser_filt)

    rows = []
    rows.append(before_after_for_method("WASP2", wasp2_orig_df, wasp2_filt_df, args.min_total))
    rows.append(before_after_for_method("GATK", gatk_orig_df, gatk_filt_df, args.min_total))
    rows.append(before_after_for_method("phASER", phaser_orig_df, phaser_filt_df, args.min_total))
    if wasp1_filt.exists():
        # For WASP1, we compare the same "original" STAR BAM counts (using WASP2 counter) against
        # counts from the WASP1-filtered BAM (also using WASP2 counter). This isolates filtering effects.
        wasp1_filt_df = parse_wasp2_counts(wasp1_filt)
        rows.append(before_after_for_method("WASP1", wasp2_orig_df, wasp1_filt_df, args.min_total))

    combined = pd.concat(rows, ignore_index=True)
    out_tsv.parent.mkdir(parents=True, exist_ok=True)
    combined.to_csv(out_tsv, sep="\t", index=False)

    # Basic stats for annotation/debugging
    with stats_path.open("w") as f:
        f.write(f"min_total: {args.min_total}\n")
        for method in ["WASP2", "GATK", "phASER"]:
            m = combined[combined["method"] == method]
            if len(m) == 0:
                f.write(f"{method}: n=0\n")
                continue
            mean_delta = float(m["delta_ref_ratio"].mean())
            median_delta = float(np.median(m["delta_ref_ratio"]))
            mean_abs_bias_before = float(np.abs(m["orig_ref_ratio"] - 0.5).mean())
            mean_abs_bias_after = float(np.abs(m["filt_ref_ratio"] - 0.5).mean())
            red = (
                (mean_abs_bias_before - mean_abs_bias_after) / mean_abs_bias_before * 100
                if mean_abs_bias_before > 0
                else 0.0
            )
            f.write(
                f"{method}: n={len(m):,} mean_delta={mean_delta:.5f} median_delta={median_delta:.5f} "
                f"mean_abs_bias {mean_abs_bias_before:.5f}->{mean_abs_bias_after:.5f} ({red:.2f}%)\n"
            )

    print(f"Wrote: {out_tsv}")
    print(f"Wrote: {stats_path}")


if __name__ == "__main__":
    main()
