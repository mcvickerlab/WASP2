# WASP2 Architecture Documentation

**Generated**: 2025-11-15
**Purpose**: High-level system architecture, design patterns, and data flow

---

## Table of Contents

1. [System Overview](#system-overview)
2. [Architectural Principles](#architectural-principles)
3. [Module Architecture](#module-architecture)
4. [Data Flow](#data-flow)
5. [Design Patterns](#design-patterns)
6. [Technology Stack](#technology-stack)
7. [Integration Points](#integration-points)
8. [Architectural Issues](#architectural-issues)

---

## System Overview

WASP2 is a **modular bioinformatics pipeline** for detecting and analyzing allele-specific patterns in genomics data.

### Core Capabilities

1. **Allele Counting** - Quantify read counts for each allele at heterozygous SNPs
2. **Imbalance Analysis** - Statistically measure allelic imbalance
3. **Mapping Bias Correction** - Remove reads with mapping bias

### Target Data Types

- Bulk RNA-seq and ATAC-seq
- Single-cell RNA-seq (scRNA-seq)
- Single-cell ATAC-seq (scATAC-seq)

### High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         WASP2 SYSTEM                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚   COUNTING   â”‚  â”‚   ANALYSIS   â”‚  â”‚   MAPPING    â”‚         â”‚
â”‚  â”‚    MODULE    â”‚  â”‚    MODULE    â”‚  â”‚    MODULE    â”‚         â”‚
â”‚  â”‚              â”‚  â”‚              â”‚  â”‚              â”‚         â”‚
â”‚  â”‚ BAM + VCF    â”‚  â”‚   Counts     â”‚  â”‚ BAM + VCF    â”‚         â”‚
â”‚  â”‚   â†“          â”‚  â”‚     â†“        â”‚  â”‚   â†“          â”‚         â”‚
â”‚  â”‚ Allele       â”‚  â”‚ Beta-        â”‚  â”‚ Allele       â”‚         â”‚
â”‚  â”‚ Counts       â”‚  â”‚ Binomial     â”‚  â”‚ Swapping     â”‚         â”‚
â”‚  â”‚              â”‚  â”‚ Model        â”‚  â”‚   â†“          â”‚         â”‚
â”‚  â”‚              â”‚  â”‚   â†“          â”‚  â”‚ Remap        â”‚         â”‚
â”‚  â”‚              â”‚  â”‚ AI Results   â”‚  â”‚   â†“          â”‚         â”‚
â”‚  â”‚              â”‚  â”‚              â”‚  â”‚ Filter       â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                                                 â”‚
â”‚  Each module: Independent | Typer CLI | Python Package          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Architectural Principles

### 1. **Modularity**

**Design**: Three independent modules with clear boundaries

```
src/
â”œâ”€â”€ counting/    # Input: BAM + VCF â†’ Output: Counts
â”œâ”€â”€ analysis/    # Input: Counts â†’ Output: AI Statistics
â””â”€â”€ mapping/     # Input: BAM + VCF â†’ Output: Filtered BAM
```

**Benefits**:
- Modules can be used independently
- Clear separation of concerns
- Easier testing and maintenance

**Trade-offs**:
- Some code duplication between modules
- Data format dependencies between modules

### 2. **CLI-First Design**

**Framework**: Typer (Python CLI framework)

**Pattern**: Each module = standalone CLI application

```python
# Example: src/counting/__main__.py
app = typer.Typer()

@app.command()
def count_variants(bam: str, vcf: str, ...):
    run_count_variants(bam, vcf, ...)
```

**Invocation**:
```bash
python -m src.counting count-variants [args]
python -m src.analysis find-imbalance [args]
python -m src.mapping make-reads [args]
```

**Benefits**:
- Self-documenting with `--help`
- Type-safe argument parsing
- Automatic validation

**Issues**:
- bin/WASP2 wrapper is incomplete/broken
- No Python API for programmatic use

### 3. **Data Pipeline Architecture**

**Pattern**: Multi-stage pipelines with intermediate files

```
Stage 1: Input â†’ Processing â†’ Intermediate Files
Stage 2: Intermediate Files â†’ Analysis â†’ Output
```

**Rationale**:
- Allows pipeline restarts at any stage
- Facilitates debugging (inspect intermediate files)
- Enables manual intervention between stages

**Trade-offs**:
- More I/O overhead
- Requires temp file management
- Disk space requirements

---

## Module Architecture

### Counting Module

**Purpose**: Extract allele-specific read counts from sequencing data

#### Component Structure

```
counting/
â”‚
â”œâ”€â”€ __main__.py          â† CLI Entry Point (Typer commands)
â”‚   â”œâ”€â”€ count_variants()       â†’ Bulk counting
â”‚   â””â”€â”€ count_variants_sc()    â†’ Single-cell counting
â”‚
â”œâ”€â”€ run_counting.py      â† Orchestrator (Bulk)
â”‚   â””â”€â”€ run_count_variants()
â”‚       â”œâ”€â”€ Validate inputs
â”‚       â”œâ”€â”€ Filter variants
â”‚       â”œâ”€â”€ Parse gene data (if regions provided)
â”‚       â”œâ”€â”€ Count alleles
â”‚       â””â”€â”€ Write output
â”‚
â”œâ”€â”€ run_counting_sc.py   â† Orchestrator (Single-Cell)
â”‚   â””â”€â”€ run_count_variants_sc()
â”‚       â””â”€â”€ Similar flow + cell barcode handling
â”‚
â”œâ”€â”€ filter_variant_data.py
â”‚   â””â”€â”€ filter_vcf_samples()
â”‚       â””â”€â”€ Filter VCF for heterozygous SNPs in samples
â”‚
â”œâ”€â”€ parse_gene_data.py
â”‚   â””â”€â”€ parse_genes()
â”‚       â””â”€â”€ Parse GTF/GFF3 annotations
â”‚
â”œâ”€â”€ count_alleles.py     â† Core Logic (Bulk)
â”‚   â””â”€â”€ count_alleles()
â”‚       â”œâ”€â”€ Read BAM with pysam
â”‚       â”œâ”€â”€ Intersect reads with SNP positions
â”‚       â”œâ”€â”€ Count ref/alt alleles
â”‚       â””â”€â”€ Return polars DataFrame
â”‚
â””â”€â”€ count_alleles_sc.py  â† Core Logic (Single-Cell)
    â””â”€â”€ count_alleles_sc()
        â”œâ”€â”€ Extract cell barcodes
        â”œâ”€â”€ Build cell Ã— SNP matrix
        â””â”€â”€ Return AnnData object
```

#### Data Flow

```
INPUT: BAM + VCF + [optional: regions, samples]
  â”‚
  â”œâ”€â†’ filter_variant_data.py
  â”‚     â””â”€â†’ Filtered VCF (heterozygous SNPs only)
  â”‚
  â”œâ”€â†’ parse_gene_data.py (if regions)
  â”‚     â””â”€â†’ Region definitions (BED format)
  â”‚
  â””â”€â†’ count_alleles.py
        â”œâ”€ Read BAM alignments (pysam)
        â”œâ”€ For each read overlapping SNP:
        â”‚    â”œâ”€ Extract base at SNP position
        â”‚    â””â”€ Increment ref/alt count
        â””â”€â†’ OUTPUT: counts.tsv or counts.h5ad

Format (TSV):
chrom  pos    ref  alt  region   ref_count  alt_count  other_count
chr1   12345  A    G    peak123  15         8          0
```

#### Key Algorithms

**Binary Search for Position Lookup**:
- SNPs sorted by position
- `bisect_left()` for O(log n) position finding
- Critical for performance with many SNPs

**Cell Barcode Handling** (Single-Cell):
- Extract CB tag from BAM
- Build sparse matrix (scipy.sparse.csr_matrix)
- Efficient for sparse single-cell data

---

### Analysis Module

**Purpose**: Statistical analysis of allelic imbalance

#### Component Structure

```
analysis/
â”‚
â”œâ”€â”€ __main__.py          â† CLI Entry Point
â”‚   â”œâ”€â”€ find_imbalance()        â†’ Bulk analysis
â”‚   â”œâ”€â”€ find_imbalance_sc()     â†’ Single-cell per-celltype
â”‚   â””â”€â”€ compare_imbalance()     â†’ Differential AI
â”‚
â”œâ”€â”€ run_analysis.py      â† Orchestrator (Bulk)
â”‚   â””â”€â”€ run_ai_analysis()
â”‚       â”œâ”€â”€ Load count data
â”‚       â”œâ”€â”€ Filter by min counts
â”‚       â”œâ”€â”€ Group by region/gene
â”‚       â””â”€â”€ Call as_analysis.get_imbalance()
â”‚
â”œâ”€â”€ as_analysis.py       â† CORE STATISTICAL ENGINE â­
â”‚   â”œâ”€â”€ get_imbalance()
â”‚   â”‚   â”œâ”€â”€ Aggregate counts by region
â”‚   â”‚   â”œâ”€â”€ Estimate dispersion (beta-binomial)
â”‚   â”‚   â”œâ”€â”€ Calculate imbalance metrics
â”‚   â”‚   â””â”€â”€ Compute p-values and FDR
â”‚   â”‚
â”‚   â”œâ”€â”€ opt_prob() / opt_unphased_dp() / opt_phased_new()
â”‚   â”‚   â””â”€â”€ Optimization functions for dispersion
â”‚   â”‚
â”‚   â””â”€â”€ bh_correction()
â”‚       â””â”€â”€ Benjamini-Hochberg FDR correction
â”‚
â”œâ”€â”€ as_analysis_sc.py    â† Single-Cell Statistics
â”‚   â”œâ”€â”€ get_imbalance_sc()
â”‚   â””â”€â”€ adata_count_qc()
â”‚       â””â”€â”€ Z-score filtering for QC
â”‚
â”œâ”€â”€ compare_ai.py        â† Differential Imbalance
â”‚   â””â”€â”€ get_compared_imbalance()
â”‚       â””â”€â”€ Compare AI between celltypes
â”‚
â”œâ”€â”€ run_analysis_sc.py   â† SC Orchestrator
â”œâ”€â”€ run_compare_ai.py    â† Comparison Orchestrator
â”œâ”€â”€ filter_data.py       â† Data validation
â””â”€â”€ count_alleles*.py    â† Utilities (some duplication with counting/)
```

#### Core Statistical Model

**Beta-Binomial Distribution**:

```
Read counts ~ BetaBinomial(n, Î±, Î²)

Where:
- n = total reads (ref + alt)
- Î±, Î² = shape parameters of beta prior
- Dispersion Ï = 1 / (Î± + Î² + 1)
```

**Null Hypothesis**: No allelic imbalance (50/50 ref/alt)

**Alternative Models**:

1. **Unphased** (default):
   - Equal probability for either haplotype
   - H0: p = 0.5 (no imbalance)

2. **Phased**:
   - Known maternal/paternal assignment
   - Can test directional imbalance

#### Optimization Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Aggregate Counts by Region                 â”‚
â”‚     ref_sum, alt_sum, total                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. Estimate Dispersion Parameter (Ï)          â”‚
â”‚     Method: Maximum Likelihood Estimation      â”‚
â”‚     Optimizer: scipy.optimize.minimize_scalar  â”‚
â”‚     Search: [0, 1] with bounds                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. Calculate Allelic Imbalance Metrics        â”‚
â”‚     - Log2(alt/ref) fold change                â”‚
â”‚     - Beta-binomial p-value                    â”‚
â”‚     - Effect size estimates                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. Multiple Testing Correction                â”‚
â”‚     Method: Benjamini-Hochberg FDR             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                OUTPUT: AI statistics per region
```

#### Data Flow

```
INPUT: counts.tsv
  â”‚
  â”œâ”€â†’ filter_data.py
  â”‚     â””â”€â†’ Filter by min_count threshold
  â”‚
  â”œâ”€â†’ Group by region/gene
  â”‚
  â”œâ”€â†’ as_analysis.py
  â”‚     â”œâ”€ For each region:
  â”‚     â”‚   â”œâ”€ Aggregate ref + alt counts
  â”‚     â”‚   â”œâ”€ Optimize dispersion parameter
  â”‚     â”‚   â”œâ”€ Calculate log2(alt/ref)
  â”‚     â”‚   â”œâ”€ Compute p-value (betabinom test)
  â”‚     â”‚   â””â”€ Estimate effect size
  â”‚     â”‚
  â”‚     â””â”€ FDR correction across all regions
  â”‚
  â””â”€â†’ OUTPUT: ai_results.tsv

Format:
region   ref_total  alt_total  log2_fc  pvalue   fdr      dispersion
peak123  150        80         -0.91    0.0023   0.045    0.012
```

---

### Mapping Module

**Purpose**: Remove allele-specific mapping bias

#### Component Structure

```
mapping/
â”‚
â”œâ”€â”€ __main__.py          â† CLI Entry Point
â”‚   â”œâ”€â”€ make_reads()         â†’ Step 1: Identify + swap
â”‚   â””â”€â”€ filter_remapped()    â†’ Step 3: Filter remapped
â”‚
â”œâ”€â”€ run_mapping.py       â† Orchestrators
â”‚   â”œâ”€â”€ run_make_remap_reads()   â†’ Step 1 orchestration
â”‚   â””â”€â”€ run_wasp_filt()          â†’ Step 3 orchestration
â”‚
â”œâ”€â”€ make_remap_reads.py  â† CORE: Allele Swapping â­
â”‚   â””â”€â”€ make_remap_reads()
â”‚       â”œâ”€â”€ Intersect BAM with VCF
â”‚       â”œâ”€â”€ Identify reads overlapping SNPs
â”‚       â”œâ”€â”€ Swap alleles at SNP positions
â”‚       â”œâ”€â”€ Write FASTQ with swapped reads
â”‚       â””â”€â”€ Track metadata for filtering
â”‚
â”œâ”€â”€ filter_remap_reads.py â† Step 3: Filter
â”‚   â””â”€â”€ filter_remap_reads()
â”‚       â”œâ”€â”€ Compare original vs remapped positions
â”‚       â”œâ”€â”€ Keep only identically mapped reads
â”‚       â””â”€â”€ Write filtered BAM
â”‚
â”œâ”€â”€ intersect_variant_data.py  â† VCF/BAM Intersection
â”‚   â””â”€â”€ intersect_bam_vcf()
â”‚       â””â”€â”€ Find reads overlapping SNP positions
â”‚
â”œâ”€â”€ wasp_data_files.py   â† File Management
â”‚   â””â”€â”€ WaspDataFiles (class)
â”‚       â”œâ”€â”€ Manage temp files
â”‚       â”œâ”€â”€ Track file paths
â”‚       â””â”€â”€ Write/read metadata JSON
â”‚
â””â”€â”€ remap_utils.py       â† Utilities
    â””â”€â”€ Helper functions
```

#### Three-Step WASP Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 1: make-reads (WASP Tool)                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  INPUT: original.bam + variants.vcf                          â”‚
â”‚     â”‚                                                        â”‚
â”‚     â”œâ”€â†’ intersect_variant_data                              â”‚
â”‚     â”‚     â””â”€ Find reads overlapping SNPs                    â”‚
â”‚     â”‚                                                        â”‚
â”‚     â”œâ”€â†’ make_remap_reads                                    â”‚
â”‚     â”‚     â”œâ”€ For each read with SNP:                        â”‚
â”‚     â”‚     â”‚   â”œâ”€ Extract read sequence                      â”‚
â”‚     â”‚     â”‚   â”œâ”€ Swap allele at SNP position(s)            â”‚
â”‚     â”‚     â”‚   â””â”€ Write to FASTQ                            â”‚
â”‚     â”‚     â”‚                                                 â”‚
â”‚     â”‚     â””â”€ Split reads into 3 categories:                â”‚
â”‚     â”‚         â”œâ”€ to_remap.bam (reads with SNPs)           â”‚
â”‚     â”‚         â”œâ”€ keep.bam (reads without SNPs)            â”‚
â”‚     â”‚         â””â”€ swapped.fq (FASTQs for remapping)        â”‚
â”‚     â”‚                                                        â”‚
â”‚     â””â”€â†’ wasp_data_files                                     â”‚
â”‚           â””â”€ Write metadata JSON                            â”‚
â”‚                                                              â”‚
â”‚  OUTPUT: swapped_r1.fq, swapped_r2.fq, metadata.json        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 2: Remap (USER'S ALIGNER - BWA/STAR/etc)              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  Example:                                                    â”‚
â”‚  $ bwa mem genome.fa swapped_r1.fq swapped_r2.fq \          â”‚
â”‚      | samtools view -b > remapped.bam                       â”‚
â”‚  $ samtools sort -o remapped.bam remapped.bam               â”‚
â”‚  $ samtools index remapped.bam                              â”‚
â”‚                                                              â”‚
â”‚  OUTPUT: remapped.bam                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 3: filter-remapped (WASP Tool)                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  INPUT: remapped.bam + metadata.json                         â”‚
â”‚     â”‚                                                        â”‚
â”‚     â”œâ”€â†’ filter_remap_reads                                  â”‚
â”‚     â”‚     â”œâ”€ For each read in remapped.bam:                â”‚
â”‚     â”‚     â”‚   â”œâ”€ Find corresponding read in to_remap.bam   â”‚
â”‚     â”‚     â”‚   â”œâ”€ Compare genomic positions                 â”‚
â”‚     â”‚     â”‚   â””â”€ KEEP if: same chr, pos, strand, CIGAR    â”‚
â”‚     â”‚     â”‚       DISCARD if: different mapping            â”‚
â”‚     â”‚     â”‚                                                 â”‚
â”‚     â”‚     â””â”€ Merge kept reads with keep.bam               â”‚
â”‚     â”‚                                                        â”‚
â”‚     â””â”€â†’ OUTPUT: wasp_filt.bam (unbiased BAM)               â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Allele Swapping Algorithm

```python
# Pseudocode
for read in bam:
    if read overlaps SNPs:
        for snp in overlapping_snps:
            # Get read base at SNP position
            read_base = read.seq[snp.read_offset]

            # Determine swap
            if read_base == snp.ref:
                swapped_base = snp.alt
            elif read_base == snp.alt:
                swapped_base = snp.ref
            else:
                continue  # Doesn't match ref or alt

            # Create swapped read
            new_seq = swap_base(read.seq, snp.read_offset, swapped_base)
            new_qual = read.qual  # Quality scores unchanged

        # Write swapped read to FASTQ
        write_fastq(read.name, new_seq, new_qual)
```

#### Metadata Management

**JSON Structure** (`wasp_data_files.json`):
```json
{
  "bam_prefix": "sample123",
  "to_remap_bam": "sample123_to_remap.bam",
  "keep_bam": "sample123_keep.bam",
  "swapped_r1": "sample123_swapped_r1.fq",
  "swapped_r2": "sample123_swapped_r2.fq",
  "read_count": 1234567,
  "snp_overlaps": 45678
}
```

**Purpose**: Links files across 3-step pipeline

---

## Data Flow

### End-to-End Workflow Example: ATAC-seq Analysis

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. MAP READS (External: BWA/Bowtie2)                          â”‚
â”‚     FASTQ â†’ Aligned BAM                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. REMOVE MAPPING BIAS (WASP Mapping Module)                  â”‚
â”‚     python -m src.mapping make-reads bam vcf                   â”‚
â”‚     [User remaps]                                               â”‚
â”‚     python -m src.mapping filter-remapped remapped.bam         â”‚
â”‚     â†’ wasp_filt.bam (unbiased)                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. COUNT ALLELES (WASP Counting Module)                       â”‚
â”‚     python -m src.counting count-variants \                    â”‚
â”‚       wasp_filt.bam variants.vcf \                             â”‚
â”‚       --samples SAMPLE123 \                                     â”‚
â”‚       --region atac_peaks.bed                                   â”‚
â”‚     â†’ counts.tsv                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. ANALYZE IMBALANCE (WASP Analysis Module)                   â”‚
â”‚     python -m src.analysis find-imbalance counts.tsv           â”‚
â”‚     â†’ ai_results.tsv                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                   RESULTS
```

### Single-Cell Workflow

```
scATAC-seq BAM (with CB tags) + VCF
          â”‚
          â”œâ”€â†’ [Optional] WASP filtering (mapping module)
          â”‚
          â”œâ”€â†’ count-variants-sc (counting module)
          â”‚     â†’ allele_counts.h5ad (AnnData)
          â”‚          cells Ã— SNPs matrix
          â”‚
          â”œâ”€â†’ find-imbalance-sc (analysis module)
          â”‚     + barcode_map.tsv (cell â†’ celltype)
          â”‚     â†’ ai_results_Tcell.tsv
          â”‚     â†’ ai_results_Bcell.tsv
          â”‚        (one file per celltype)
          â”‚
          â””â”€â†’ compare-imbalance (analysis module)
                â†’ ai_comparison_Tcell_vs_Bcell.tsv
                   (differential AI between celltypes)
```

---

## Design Patterns

### 1. **Orchestrator Pattern**

**Structure**:
```
__main__.py (CLI)
    â†“
run_*.py (Orchestrator)
    â†“
core_logic.py (Worker functions)
```

**Example** (Counting):
```python
# __main__.py - CLI interface
@app.command()
def count_variants(bam, vcf, ...):
    run_count_variants(bam, vcf, ...)

# run_counting.py - Orchestrator
def run_count_variants(bam, vcf, ...):
    # 1. Validate inputs
    # 2. Filter VCF
    # 3. Parse genes
    # 4. Count alleles
    # 5. Write output

# count_alleles.py - Worker
def count_alleles(bam, vcf, ...):
    # Core counting logic
```

**Benefits**:
- Separation of concerns
- CLI logic separate from business logic
- Easier testing (test orchestrator independently)

### 2. **File-Based Data Passing**

**Pattern**: Modules communicate via files, not in-memory objects

```
Module A â†’ writes file.txt â†’ Module B reads file.txt
```

**Rationale**:
- Language-agnostic (could rewrite modules in other languages)
- Checkpointing (restart pipeline mid-way)
- Debugging (inspect intermediate files)

**Trade-offs**:
- I/O overhead
- Type safety only at file format level
- No compiler checking of interfaces

### 3. **Temporary File Management**

**Pattern**: Decorator for temp file cleanup

```python
@tempfile_wrapper(temp_loc, keep_temp)
def process_data(...):
    # Use temp files
    # Decorator handles cleanup
```

**Issues Found**:
- Not consistently used across modules
- Some temp files may leak
- Error paths may not clean up

### 4. **Lazy Loading for Large Files**

**Pattern**: Use polars lazy evaluation

```python
# Don't load entire file
df = pl.scan_csv("huge.vcf")
      .filter(pl.col("QUAL") > 30)
      .collect()  # Only now loads filtered data
```

**Benefits**: Memory efficiency

**Usage**: Inconsistent - not used everywhere it could be

---

## Technology Stack

### Layer Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             CLI Layer (Typer)                  â”‚
â”‚  User-facing commands, argument parsing        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Orchestration Layer (run_*.py)         â”‚
â”‚  Workflow management, validation, I/O          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Business Logic Layer                   â”‚
â”‚  Counting, statistics, allele swapping         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Data Access Layer                      â”‚
â”‚  pysam: BAM/VCF I/O                           â”‚
â”‚  polars/pandas: DataFrame operations           â”‚
â”‚  scipy: Statistical functions                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Dependency Usage by Layer

| Layer | Dependencies | Purpose |
|-------|--------------|---------|
| CLI | typer, typing_extensions | Command interface |
| Orchestration | pathlib, tempfile | File management |
| Business Logic | numpy, polars, pandas | Data processing |
| Statistics | scipy, numpy | Beta-binomial models |
| Bioinformatics | pysam, pybedtools | File I/O |
| Single-Cell | anndata, scipy.sparse | H5AD format |

---

## Integration Points

### Module Interfaces

#### Counting â†’ Analysis

**Contract**: TSV file with specific columns

```
Required columns:
- chrom: str
- pos: int
- ref: str (single base)
- alt: str (single base)
- ref_count: int
- alt_count: int

Optional columns:
- region: str (for ATAC peaks)
- gene_id: str (for RNA-seq)
- transcript_id: str (for RNA-seq)
```

**Issue**: âš ï¸ No formal schema validation

#### Mapping â†’ Counting

**Contract**: Filtered BAM file

- Must be sorted
- Must be indexed (.bai file)
- Compatible with pysam

**Issue**: âš ï¸ No verification that BAM is WASP-filtered

#### Single-Cell Format

**Contract**: AnnData H5AD file

```python
adata structure:
    .X: sparse matrix (cells Ã— SNPs) with allele counts
    .obs: cell metadata
    .var: SNP metadata (chrom, pos, ref, alt)
    .uns: unstructured metadata (samples, etc.)
```

### External Tool Integration

**Mapping Module Step 2**: User must run external aligner

```bash
# WASP provides input FASTQs
# User runs their aligner of choice:
bwa mem ...
# or
STAR ...
# or
bowtie2 ...
```

**Issue**: âš ï¸ No validation of user's aligner output

---

## Architectural Issues

### ðŸ”´ Critical Issues

1. **bin/WASP2 Main Executable is Broken**
   - Only supports 2 of 3 modules
   - Hardcoded to wrong module
   - Contains TODO comment
   - **Impact**: Users can't use main executable
   - **Recommendation**: Fix or deprecate

2. **No Test Suite**
   - Zero unit tests found
   - Zero integration tests
   - No CI/CD
   - **Impact**: Regression risk, hard to refactor
   - **Recommendation**: Phase 2 priority

3. **No Shared Utilities Library**
   - Code duplication between modules
   - E.g., `count_alleles.py` exists in both counting/ and analysis/
   - **Impact**: Bug fixes must be applied multiple times
   - **Recommendation**: Extract common code to shared lib

### ðŸŸ¡ Medium Issues

4. **Inconsistent Error Handling**
   - No custom exception hierarchy
   - Inconsistent try/except patterns
   - **Impact**: Poor user experience, hard debugging
   - **Recommendation**: Standardize in Phase 2

5. **No Type Hints**
   - Functions lack type annotations
   - **Impact**: IDE support poor, runtime errors
   - **Recommendation**: Add type hints in Phase 2

6. **Pandas + Polars Redundancy**
   - Both used throughout
   - Unclear when to use which
   - **Impact**: Larger dependency footprint, confusion
   - **Recommendation**: Document guidelines or consolidate

7. **Limited Configuration**
   - Hard-coded constants
   - No config file support
   - **Impact**: Users can't tune parameters easily
   - **Recommendation**: Add config system

### ðŸŸ¢ Minor Issues

8. **TODO Comments in Production Code**
   - "TODO GOTTA TEST THIS" in all 3 `__main__.py` files
   - **Impact**: Unclear if CLIs are tested
   - **Recommendation**: Remove or implement

9. **No Logging Framework**
   - Print statements instead of logging
   - No log levels
   - **Impact**: Production debugging difficult
   - **Recommendation**: Implement logging in Phase 2

10. **Temporary File Leaks Possible**
    - Cleanup not guaranteed in error paths
    - **Impact**: Disk space issues
    - **Recommendation**: Use context managers consistently

---

## Architectural Strengths

### âœ… Good Design Choices

1. **Modular Structure**
   - Clean separation between counting/analysis/mapping
   - Can use modules independently

2. **File-Based Interfaces**
   - Language-agnostic
   - Easy to checkpoint and debug
   - Users can inspect intermediate files

3. **Typer CLI Framework**
   - Modern, type-safe CLI
   - Auto-generated help
   - Good user experience

4. **Single-Cell Support**
   - Well-integrated scRNA/scATAC workflows
   - Uses standard formats (H5AD/AnnData)
   - Compatible with scanpy ecosystem

5. **Statistical Rigor**
   - Beta-binomial model is appropriate
   - FDR correction included
   - Phased/unphased support

---

## Recommended Architectural Improvements

### Phase 2 Priorities

1. **Create Shared Utilities Package**
   ```
   src/
   â”œâ”€â”€ common/
   â”‚   â”œâ”€â”€ __init__.py
   â”‚   â”œâ”€â”€ bam_utils.py
   â”‚   â”œâ”€â”€ vcf_utils.py
   â”‚   â”œâ”€â”€ file_utils.py
   â”‚   â””â”€â”€ validation.py
   â”œâ”€â”€ counting/
   â”œâ”€â”€ analysis/
   â””â”€â”€ mapping/
   ```

2. **Add Schema Validation**
   - Validate TSV files before processing
   - Check BAM/VCF format compliance
   - Clear error messages for invalid inputs

3. **Implement Logging**
   ```python
   import logging
   logger = logging.getLogger(__name__)
   logger.info("Processing BAM file...")
   ```

4. **Add Type Hints**
   ```python
   def count_alleles(
       bam_path: Path,
       vcf_path: Path,
       min_qual: int = 20
   ) -> pl.DataFrame:
       ...
   ```

5. **Fix bin/WASP2**
   - Properly route to modules
   - Or document as deprecated, use `python -m src.module` instead

---

## Future Architecture Considerations

### Scalability

**Current Limitations**:
- Single-threaded processing (mostly)
- Limited parallelization
- Memory-intensive for large files

**Potential Improvements**:
- Parallelize chromosome processing
- Use Dask for out-of-core computing
- Implement streaming for BAM files

### Python API

**Current**: CLI-only interface

**Future**: Provide programmatic API
```python
from wasp2 import count_variants, analyze_imbalance

counts = count_variants(bam="data.bam", vcf="variants.vcf")
results = analyze_imbalance(counts, min_count=10)
```

### Plugin Architecture

**Future**: Allow custom statistical models
```python
from wasp2.analysis import register_model

@register_model("custom-beta-binomial")
def my_model(counts, params):
    ...
```

---

## Summary

### Architecture Type
**Modular Pipeline Architecture** with file-based interfaces

### Strengths
- Clear module boundaries
- Flexible workflows
- Standard file formats
- Statistical rigor

### Weaknesses
- Code duplication
- No tests
- Broken main executable
- Limited configuration

### Phase 1 Status
- âœ… **Task 1.1.1**: Directory structure documented
- âœ… **Task 1.1.2**: Dependencies analyzed
- âœ… **Task 1.1.3**: Architecture documented (this file)

### Next Steps
- Commit Phase 1.1 deliverables
- Begin Phase 1.2: Module deep dives (starting with Counting)

---

**Document Version**: 1.0
**Last Updated**: 2025-11-15
**Next Review**: After Phase 1.2 (Counting module deep dive)
